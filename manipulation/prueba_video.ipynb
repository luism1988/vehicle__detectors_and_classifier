{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRUEBA DETECCION DE VEHICULOS EN VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our body classifier\n",
    "car_classifier = cv2.CascadeClassifier(('../datasets/haarcascade_car.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n",
      "fps: 30.0\n"
     ]
    }
   ],
   "source": [
    "# Initiate video capture for video file\n",
    "#cap = cv2.VideoCapture(\"videos/autovia.mp4\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FPS,20)\n",
    "\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"fps:\",fps)\n",
    "while True:\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(\"fps:\",fps)\n",
    "    # Read first frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:  # Check if frame is successfully read\n",
    "        break\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) ==13: #13 is the Enter Key\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.VideoCapture 0000022CEDD23430>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop once video is successfully loaded\n",
    "while True:\n",
    "    \n",
    "    # Read first frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:  # Check if frame is successfully read\n",
    "        break\n",
    "        \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "   \n",
    "    # Pass frame to our car classifier\n",
    "    cars = car_classifier.detectMultiScale(gray,scaleFactor=1.05, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    # Extract bounding boxes for any bodies identified\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        \n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) ==13: #13 is the Enter Key\n",
    "        break\n",
    "    \n",
    "    # Wait for 100 ms (10 FPS)\n",
    "    #time.sleep(100)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificar los FPS para que el video se vea en tiempo real. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load car classifier\n",
    "car_classifier = cv2.CascadeClassifier('../dataset/haarcascade_car.xml')\n",
    "\n",
    "# Load video file\n",
    "cap = cv2.VideoCapture('video_salida.mp4')\n",
    "\n",
    "# Set video FPS to 20\n",
    "cap.set(cv2.CAP_PROP_FPS, 20)\n",
    "\n",
    "# Loop over the frames from the video\n",
    "while cap.isOpened():\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect cars in the frame\n",
    "    cars = car_classifier.detectMultiScale(gray, 1.4, 2)\n",
    "    \n",
    "    # Draw bounding boxes around the cars\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # Wait for user input to move to the next frame\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### guardar una imagen partiendo de un array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "img3 = Image.fromarray(images[\"train\"][\"ale\"][0][y:y+h,x:x+w])\n",
    "img3.save('imagen.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guarda las detecciones en imagenes, que despues las puedes usar de data set para clasificarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Load car classifier\n",
    "car_classifier = cv2.CascadeClassifier('../dataset/cars.xml')\n",
    "\n",
    "# Load video file\n",
    "cap = cv2.VideoCapture('video_salida.mp4')\n",
    "\n",
    "# Set video FPS to 20\n",
    "cap.set(cv2.CAP_PROP_FPS, 15)\n",
    "\n",
    "# Create a directory to store the detected images if it does not exist\n",
    "if not os.path.exists('detecciones'):\n",
    "    os.makedirs('detecciones')\n",
    "x_contador = 0\n",
    "# Loop over the frames from the video\n",
    "while cap.isOpened():\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect cars in the frame\n",
    "    cars = car_classifier.detectMultiScale(gray,scaleFactor=1.05, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    # Draw bounding boxes around the cars\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        \n",
    "    # Save image of each detected frame\n",
    "    for i, (x,y,w,h) in enumerate(cars):\n",
    "        \n",
    "        # Extract image of the detected car\n",
    "        car_image = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Save image of the detected car in JPEG format in the 'detecciones' folder\n",
    "        cv2.imwrite(os.path.join('detecciones', f'carro_{x_contador}.jpg'), car_image)\n",
    "        x_contador += 1\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # Wait for user input to move to the next frame\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiar el tamaño de los fotogramas de video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "for i in range(22,23):\n",
    "    cap = cv2.VideoCapture(f'videos/mer{i}_mod.mp4')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    out = cv2.VideoWriter(f'mer_{i}_mod_30fps.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30, (720, 960))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_resized = cv2.resize(frame, (720, 960))\n",
    "        out.write(frame_resized)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intentado definir una region de interes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect cars in the lower half of the frame\n",
    "height, width = frame.shape[:2]\n",
    "bottom_half = gray[height//2:, :]\n",
    "cars = car_classifier.detectMultiScale(bottom_half, scaleFactor=1.05, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Adjust the detected car coordinates to the full frame\n",
    "for i in range(len(cars)):\n",
    "    x, y, w, h = cars[i]\n",
    "    cars[i] = (x, y+height//2, w, h)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deteccion de vehiculo en área de interes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luism\\Desktop\\car_detectors_and_classifier\\manipulation\\prueba_video.ipynb Cell 18\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m roi \u001b[39m=\u001b[39m gray[y1:y2,x1:x2]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#X23sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m#gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#X23sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m cars \u001b[39m=\u001b[39m car_classifier\u001b[39m.\u001b[39;49mdetectMultiScale(roi, scaleFactor\u001b[39m=\u001b[39;49m\u001b[39m1.05\u001b[39;49m, minNeighbors\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, minSize\u001b[39m=\u001b[39;49m(\u001b[39m50\u001b[39;49m, \u001b[39m50\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#X23sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#cars = car_classifier.detectMultiScale(gray, 1.4, 2)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#X23sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#X23sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Draw bounding boxes around the cars\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#X23sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mfor\u001b[39;00m (x,y,w,h) \u001b[39min\u001b[39;00m cars:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load car classifier\n",
    "car_classifier = cv2.CascadeClassifier('../dataset/cars.xml')\n",
    "\n",
    "# Load video file\n",
    "cap = cv2.VideoCapture('mer1_mod.mp4')\n",
    "\n",
    "# Set video FPS to 20\n",
    "cap.set(cv2.CAP_PROP_FPS, 20)\n",
    "\n",
    "# Loop over the frames from the video\n",
    "while cap.isOpened():\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect cars in the frame\n",
    "    # Define las coordenadas del ROI\n",
    "    x1, y1 = 100, 550\n",
    "    x2, y2 = 720, 650\n",
    "\n",
    "    # Dibuja un rectángulo sobre la imagen original\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, ), 2)\n",
    "\n",
    "    roi = gray[y1:y2,x1:x2]\n",
    "    #gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    cars = car_classifier.detectMultiScale(roi, scaleFactor=1.05, minNeighbors=5, minSize=(50, 50))\n",
    "\n",
    "    #cars = car_classifier.detectMultiScale(gray, 1.4, 2)\n",
    "    \n",
    "    # Draw bounding boxes around the cars\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x+x1, y+y1), (x+x1+w, y+y1+h), (0, 255, 255), 2)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # Wait for user input to move to the next frame\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deteccion de vehiculo en área de interes y etiqueta generica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load car classifier\n",
    "car_classifier = cv2.CascadeClassifier('../datasets/cars.xml')\n",
    "\n",
    "# Load video file\n",
    "cap = cv2.VideoCapture('mer1_mod.mp4')\n",
    "\n",
    "# Set video FPS to 20\n",
    "cap.set(cv2.CAP_PROP_FPS, 10)\n",
    "\n",
    "# Loop over the frames from the video\n",
    "while cap.isOpened():\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect cars in the frame\n",
    "    # Define las coordenadas del ROI\n",
    "    x1, y1 = 100, 550\n",
    "    x2, y2 = 720, 650\n",
    "\n",
    "    # Dibuja un rectángulo sobre la imagen original\n",
    " \n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, ), 2)\n",
    "    roi = gray[y1:y2,x1:x2]\n",
    "    #gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    cars = car_classifier.detectMultiScale(roi, scaleFactor=1.05, minNeighbors=5, minSize=(50, 50))\n",
    "\n",
    "    #cars = car_classifier.detectMultiScale(gray, 1.4, 2)\n",
    "    \n",
    "    # Draw bounding boxes around the cars\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in cars:\n",
    "        texto = \"Prueba\"\n",
    "        posicion_etiqueta = (x + x1, y + y1 - 10)\n",
    "        cv2.rectangle(frame, (x+x1, y+y1), (x+x1+w, y+y1+h), (0, 255, 255), 2)\n",
    "        cv2.putText(frame, texto, posicion_etiqueta, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # Wait for user input to move to the next frame\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deteccion de vehiculo en área de interes y guardado de imagen en format jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luism\\Desktop\\vehicle_detector_and_classifier\\manipulation\\prueba_video.ipynb Cell 22\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/vehicle_detector_and_classifier/manipulation/prueba_video.ipynb#X30sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#count for enuerate the image\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/vehicle_detector_and_classifier/manipulation/prueba_video.ipynb#X30sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Loop over the frames from the video\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/vehicle_detector_and_classifier/manipulation/prueba_video.ipynb#X30sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mwhile\u001b[39;00m cap\u001b[39m.\u001b[39misOpened():\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/vehicle_detector_and_classifier/manipulation/prueba_video.ipynb#X30sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# Read the next frame from the video\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/vehicle_detector_and_classifier/manipulation/prueba_video.ipynb#X30sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39;49mread()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/vehicle_detector_and_classifier/manipulation/prueba_video.ipynb#X30sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ret:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/vehicle_detector_and_classifier/manipulation/prueba_video.ipynb#X30sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from keras.models import load_model\n",
    "# Load car classifier\n",
    "car_classifier = cv2.CascadeClassifier('../datasets/cars.xml')\n",
    "for i in range (22,61):\n",
    "    # Load video file\n",
    "    cap = cv2.VideoCapture(f'mer_{i}_mod.mp4')\n",
    "\n",
    "    # Set video FPS to 20\n",
    "    cap.set(cv2.CAP_PROP_FPS,1)\n",
    "    #count for enuerate the image\n",
    "    # Loop over the frames from the video\n",
    "\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # Read the next frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect cars in the frame\n",
    "        # Define las coordenadas del ROI\n",
    "        x1, y1 = 0, 0\n",
    "        x2, y2 = 720, 960\n",
    "\n",
    "        # Dibuja un rectángulo sobre la imagen original\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, ), 2)\n",
    "\n",
    "        roi = gray[y1:y2,x1:x2]\n",
    "        #gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        cars = car_classifier.detectMultiScale(roi, scaleFactor=1.05, minNeighbors=5, minSize=(50, 50))\n",
    "        \n",
    "        \n",
    "        # Save image of each detected frame\n",
    "        for i, (x,y,w,h) in enumerate(cars):\n",
    "            x += x1\n",
    "            y += y1\n",
    "        \n",
    "            # Extract image of the detected car\n",
    "            car_image = frame[y:y+h, x:x+w]\n",
    "            x_contador = random.randint(0, 10000)\n",
    "            # Save image of the detected car in JPEG format in the 'detecciones' folder\n",
    "            if  car_image.shape >=(50,50,3):\n",
    "                cv2.imwrite(os.path.join('detecciones', f'vehicle_{x_contador}.jpg'), car_image)\n",
    "                x_contador += 1\n",
    "\n",
    "        # Draw bounding boxes around the cars\n",
    "        for (x,y,w,h) in cars:\n",
    "            cv2.rectangle(frame, (x+x1, y+y1), (x+x1+w, y+y1+h), (0, 255, 255), 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "        # Wait for user input to move to the next frame\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deteccion de vehiculo en área de interes y prediccion con etiqueta \n",
    "No funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 72)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:72\u001b[1;36m\u001b[0m\n\u001b[1;33m    cv2.imshow('frame', frame)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load car classifier\n",
    "car_classifier = cv2.CascadeClassifier('../datasets/cars.xml')\n",
    "\n",
    "# Load video file\n",
    "cap = cv2.VideoCapture('mer1_mod.mp4')\n",
    "\n",
    "# Set video FPS to 20\n",
    "cap.set(cv2.CAP_PROP_FPS, 10)\n",
    "\n",
    "\n",
    "#load model\n",
    "modelt = load_model(\"../nn_model_vgg_19.h5\")\n",
    "names = ['bus', 'car', 'truck']\n",
    "\n",
    "# Loop over the frames from the video\n",
    "while cap.isOpened():\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect cars in the frame\n",
    "    # Define las coordenadas del ROI\n",
    "    x1, y1 = 100, 550\n",
    "    x2, y2 = 720, 650\n",
    "\n",
    "    # Dibuja un rectángulo ROI sobre la imagen original\n",
    " \n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, ), 2)\n",
    "    roi = gray[y1:y2,x1:x2]\n",
    "    cars = car_classifier.detectMultiScale(roi, scaleFactor=1.05, minNeighbors=5, minSize=(50, 50))\n",
    "\n",
    "    #cars = car_classifier.detectMultiScale(gray, 1.4, 2)\n",
    "    \n",
    "    # Draw bounding boxes around the cars\n",
    "    \n",
    "    for (x,y,w,h) in cars:\n",
    "        #texto = \"Prueba\"\n",
    "        posicion_etiqueta = (x + x1, y + y1 - 10)\n",
    "        cv2.rectangle(frame, (x+x1, y+y1), (x+x1+w, y+y1+h), (0, 255, 255), 2)\n",
    "        #hacer la clasificacion\n",
    "  \n",
    "        # Extract image of the detected car\n",
    "     \n",
    "        vehicle_image_to_classifier = frame[(y+y1):(y+y1+h), (x + x1):(x + x1+w)]#Imagen a clasificar\n",
    "        #clasificar la seleccion:\n",
    "        plt.imshow(cv2.cvtColor(np.asarray(imaget),cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        imaget=cv2.resize(cv2.imread(vehicle_image_to_classifier), (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        xt = np.asarray(imaget)\n",
    "        xt=preprocess_input(xt)\n",
    "        xt = np.expand_dims(xt,axis=0)\n",
    "        preds = modelt.predict(xt)\n",
    "\n",
    "\n",
    "        #Colocar etiqueta\n",
    "        cv2.putText(frame, names[np.argmax(preds)], posicion_etiqueta, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # Wait for user input to move to the next frame\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deteccion de vehiculo en área de interes y prediccion con etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 494ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load car classifier\n",
    "car_classifier = cv2.CascadeClassifier('../datasets/cars.xml')\n",
    "\n",
    "# Load video file\n",
    "cap = cv2.VideoCapture('videos/mer1_mod.mp4')\n",
    "\n",
    "# Set video FPS to 20\n",
    "cap.set(cv2.CAP_PROP_FPS, 1)\n",
    "\n",
    "\n",
    "#load model\n",
    "modelt = load_model(\"../nn_model_vgg_19.h5\")\n",
    "names = ['bus', 'car', 'truck']\n",
    "\n",
    "# Loop over the frames from the video\n",
    "while cap.isOpened():\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect cars in the frame\n",
    "  \n",
    " \n",
    "    cars = car_classifier.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=5, minSize=(50, 50))\n",
    "\n",
    "    \n",
    "    # Draw bounding boxes and labels around the vehicles \n",
    "    \n",
    "    for (x,y,w,h) in cars:\n",
    "        #texto = \"Prueba\"\n",
    "        posicion_etiqueta = (x , y - 10)\n",
    "        \n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        \n",
    "        #hacer la clasificacion\n",
    "        # Extract image of the detected car\n",
    "        \n",
    "        vehicle_image_to_classifier = frame[y:y+h, x:x+w]#Imagen a clasificar\n",
    "\n",
    "        #clasificar la seleccion:\n",
    "        imaget=cv2.resize(vehicle_image_to_classifier, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        xt = np.asarray(imaget)\n",
    "        xt = preprocess_input(xt)\n",
    "        xt = np.expand_dims(xt,axis=0)\n",
    "        preds = modelt.predict(xt)\n",
    "\n",
    "        #Colocar etiqueta\n",
    "        cv2.putText(frame, names[np.argmax(preds)], posicion_etiqueta, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # Wait for user input to move to the next frame\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
